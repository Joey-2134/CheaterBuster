{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Model Training\n",
    "---\n",
    "In this file, I will train the model using the prepared dataset using scikit-learn."
   ],
   "id": "232e3200253fd2ac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T10:44:46.480900Z",
     "start_time": "2025-11-05T10:42:23.224080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from Utils import setup_database_connection, true, false\n",
    "from Utils import load_all_players\n",
    "from Utils import COLOUR_BANNED, COLOUR_NON_BANNED, COLOUR_BLUE\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "engine = setup_database_connection()\n",
    "player_data = load_all_players(engine)\n",
    "banned_player_data = player_data[player_data['has_ban'] == true]\n",
    "non_banned_player_data = player_data[player_data['has_ban'] == false]"
   ],
   "id": "5760e726e6c875e6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to database...\n",
      "Connection successful!\n",
      "Loaded 214688 players\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "iiopm7cms4k",
   "source": [
    "## Data Cleaning\n",
    "---\n",
    "Apply data cleaning to prepare the dataset for training:\n",
    "1. Remove features with >50% zero values in banned player data\n",
    "2. Remove players with >2 zero values across features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "rbn1lpbcngj",
   "source": [
    "features_to_exclude = []\n",
    "for feature in banned_player_data.select_dtypes(include=['int64', 'float64']).columns:\n",
    "    banned_zeros = (banned_player_data[feature] == 0).sum()\n",
    "    banned_zero_pct = (banned_zeros / len(banned_player_data)) * 100\n",
    "\n",
    "    if banned_zero_pct > 50:\n",
    "        features_to_exclude.append(feature)\n",
    "\n",
    "thresholded_player_data = player_data.drop(columns=features_to_exclude)\n",
    "\n",
    "ZERO_THRESHOLD = 2\n",
    "\n",
    "numeric_features = thresholded_player_data.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "zero_counts_per_player = (thresholded_player_data[numeric_features] == 0).sum(axis=1)\n",
    "\n",
    "mask = zero_counts_per_player <= ZERO_THRESHOLD\n",
    "\n",
    "filtered_player_data = thresholded_player_data[mask].copy()\n",
    "\n",
    "original_banned_count = (thresholded_player_data['has_ban'] == true).sum()\n",
    "original_non_banned_count = (thresholded_player_data['has_ban'] == false).sum()\n",
    "filtered_banned_count = (filtered_player_data['has_ban'] == true).sum()\n",
    "filtered_non_banned_count = (filtered_player_data['has_ban'] == false).sum()\n",
    "\n",
    "total_original = len(thresholded_player_data)\n",
    "total_filtered = len(filtered_player_data)\n",
    "total_removed = total_original - total_filtered\n",
    "banned_removed = original_banned_count - filtered_banned_count\n",
    "non_banned_removed = original_non_banned_count - filtered_non_banned_count\n",
    "\n",
    "print(f\"{'Category':<20} {'Original':<15} {'Filtered':<15} {'Removed':<15} {'% Retained':<15}\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Banned Players':<20} {original_banned_count:<15,} {filtered_banned_count:<15,} {banned_removed:<15,} {(filtered_banned_count/original_banned_count*100):.2f}%\")\n",
    "print(f\"{'Non-Banned Players':<20} {original_non_banned_count:<15,} {filtered_non_banned_count:<15,} {non_banned_removed:<15,} {(filtered_non_banned_count/original_non_banned_count*100):.2f}%\")\n",
    "print(f\"{'Total Players':<20} {total_original:<15,} {total_filtered:<15,} {total_removed:<15,} {(total_filtered/total_original*100):.2f}%\")\n",
    "\n",
    "print(f\"\\nClass Balance:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Original - Banned: {(original_banned_count/total_original*100):.2f}% | Non-Banned: {(original_non_banned_count/total_original*100):.2f}%\")\n",
    "print(f\"Filtered - Banned: {(filtered_banned_count/total_filtered*100):.2f}% | Non-Banned: {(filtered_non_banned_count/total_filtered*100):.2f}%\")\n",
    "\n",
    "print(f\"\\nData cleaning complete. Ready for training with {len(filtered_player_data):,} players and {filtered_player_data.shape[1]} features\")"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T10:44:46.648017Z",
     "start_time": "2025-11-05T10:44:46.488824Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category             Original        Filtered        Removed         % Retained     \n",
      "--------------------------------------------------------------------------------\n",
      "Banned Players       43,964          22,232          21,732          50.57%\n",
      "Non-Banned Players   170,724         168,744         1,980           98.84%\n",
      "Total Players        214,688         190,976         23,712          88.96%\n",
      "\n",
      "Class Balance:\n",
      "--------------------------------------------------\n",
      "Original - Banned: 20.48% | Non-Banned: 79.52%\n",
      "Filtered - Banned: 11.64% | Non-Banned: 88.36%\n",
      "\n",
      "Data cleaning complete. Ready for training with 190,976 players and 29 features\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Handling Class Imbalance\n",
    "---\n",
    "I will be using both undersampling and oversampling techniques to handle class imbalance in the dataset. I have too little banned players in my dataset in comparison to non banned players. I will be using scikit learns SMOTEENN method to oversample the banned players and undersample the non banned players."
   ],
   "id": "f3dd34682f51d9be"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T11:08:18.499871Z",
     "start_time": "2025-11-05T11:05:56.683407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "columns_to_exclude = ['steam_id', 'created_at', 'name', 'total_matches', 'updated_at', 'has_ban']\n",
    "X = filtered_player_data.drop(columns=columns_to_exclude)\n",
    "y = filtered_player_data['has_ban'].map({true: 1, false: 0})\n",
    "\n",
    "smote_enn = SMOTEENN(random_state=42)\n",
    "X_res, y_res = smote_enn.fit_resample(X, y)\n",
    "\n",
    "print(f\"Original dataset shape: {X.shape}\")\n",
    "print(f\"Resampled dataset shape: {X_res.shape}\")\n",
    "print(f\"\\nOriginal class distribution:\")\n",
    "print(f\"  Banned: {(y == 1).sum():,} ({(y == 1).sum()/len(y)*100:.2f}%)\")\n",
    "print(f\"  Non-banned: {(y == 0).sum():,} ({(y == 0).sum()/len(y)*100:.2f}%)\")\n",
    "print(f\"\\nResampled class distribution:\")\n",
    "print(f\"  Banned: {(y_res == 1).sum():,} ({(y_res == 1).sum()/len(y_res)*100:.2f}%)\")\n",
    "print(f\"  Non-banned: {(y_res == 0).sum():,} ({(y_res == 0).sum()/len(y_res)*100:.2f}%)\")\n",
    "\n"
   ],
   "id": "a9388eb04d68fdef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (190976, 23)\n",
      "Resampled dataset shape: (303573, 23)\n",
      "\n",
      "Original class distribution:\n",
      "  Banned: 22,232 (11.64%)\n",
      "  Non-banned: 168,744 (88.36%)\n",
      "\n",
      "Resampled class distribution:\n",
      "  Banned: 167,552 (55.19%)\n",
      "  Non-banned: 136,021 (44.81%)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Resampling Results\n",
    "---\n",
    "I went from 22000 banned players up to 167,000 and undersampled non banned players from 168,744 to 136,021, giving me a much more balanced dataset to train on. approx 55/45 split.\n",
    "\n",
    "# Performance Metrics\n",
    "---\n",
    "Before I start training the model and choosing an algorithm, I will decide on what metrics I want to prioritise. Given we are trying to identify cheaters and crucially without incorrectly flagging legit players as cheaters I want to reduce the number of false positives, therefore prioritising Precision as my main metric. I would rather miss some cheaters (false negatives) than incorrectly flag legit players (false positives). I will also monitor Recall, but it will be a secondary metric to Precision. Preferably a good balance would be optimal.\n",
    "\n",
    "# Algorithm Selection\n",
    "---\n",
    "I will start with XGBoost as it's a high performance algorithm as it works well my tabular data, however if I am not happy with the performance, I may try others such as Random Forest."
   ],
   "id": "a96bb83e719b6c51"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7f50a5d489c81c70"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
